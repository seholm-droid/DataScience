{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6858f6",
   "metadata": {},
   "source": [
    "## Data Science: Final Project\n",
    "* [Task 1: Balancing the Dataset](#first-bullet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d55cab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import sys\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513b3af0",
   "metadata": {},
   "source": [
    "### Task 1: Knowing our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d61d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the fake news corpus\n",
    "corpus_news = pd.read_csv('cleaned.csv')\n",
    "corpus_news = corpus_news[['content', 'type']].drop_duplicates().dropna(axis = 0, how = 'any')\n",
    "\n",
    "# Reading the scraped data\n",
    "scraped_news = pd.read_csv('cleaned_scraped_data.csv')\n",
    "scraped_news = scraped_news[['content','type']].drop_duplicates().dropna(axis = 0, how = 'any')\n",
    "\n",
    "# Mergin' the data (We need to clean the scraped news as welL!)\n",
    "all_news = corpus_news.append(scraped_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4126f89",
   "metadata": {},
   "source": [
    "#### Making news grouping\n",
    "We need to make two classification categories from 12 possible categories. There are several ways to do this. An obvious approach would be to put all types labeled fake in one category and everything else in another. What we care about is distinguishing between whether something is fake news or not. We do not not care about identifying e.g. hate articles, clickbait or junksci. We just use these types as examples of something that is not fake news even though these are also undeseriable article types on e.g. a news platform.We do not believe, that a classifier will be able to distinguish between satire and fake news, therefore we remove the satire articles entirely. \n",
    "\n",
    "#### Balancing the Dataset\n",
    "The handed out fake news dataset is imbalanced as the non fake news articles constitute almost twice as many articles (after filteren nans) than the rest of the data. Furthmore within the non-fake news data reliable articles only constitute a small percentage. Therefore we enrich this data with the scraped data and then we random remove articles from the non-fake news data to get the same amount of articles in each dataset. Here it is important to note, that we assume, that the wikinews articles are reliable. Going from an imbalanced to balanced dataset improves our baseline accuracy around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfbbf719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of not fake news: 110071\n",
      "Length of fake news: 110071\n",
      "Length of all news: 220142\n"
     ]
    }
   ],
   "source": [
    "# Classifying types\n",
    "remove = ['unknown', 'satire']\n",
    "fake = ['fake']\n",
    "not_fake = ['political', 'reliable', 'bias', 'conspiracy', 'rumor', 'unreliable', 'clickbait', 'junksci', 'hate']\n",
    "\n",
    "all_news = all_news[~all_news['type'].isin(remove)]\n",
    "fake_news = all_news[all_news['type'].isin(fake)].copy()\n",
    "not_fake_news = all_news[all_news['type'].isin(not_fake)].copy()\n",
    "not_fake_news['type'] = 'not fake' \n",
    "\n",
    "# Number of articles in each set\n",
    "count_group_1 = len(fake_news)\n",
    "count_group_2 = len(not_fake_news)\n",
    "\n",
    "not_fake_news = not_fake_news.sample(n=count_group_1)\n",
    "\n",
    "all_news = not_fake_news.append(fake_news)\n",
    "all_news.to_csv('all_news.csv')\n",
    "\n",
    "print(f'Length of not fake news: {len(not_fake_news)}')\n",
    "print(f'Length of fake news: {len(fake_news)}')\n",
    "print(f'Length of all news: {len(all_news)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a5ffd8",
   "metadata": {},
   "source": [
    "#### Task 2: Establishing a Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a151e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_news = pd.read_csv('all_news.csv')\n",
    "all_news['type'] = all_news['type'].map({'fake':1, 'not fake':0})\n",
    "\n",
    "x = all_news['content'].values\n",
    "y = all_news['type'].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=1000)\n",
    "\n",
    "# Apply tfid vectorization\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(x_train)\n",
    "x_train = vectorizer.transform(x_train) #.toarray()\n",
    "x_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1ee8650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for logistic baseline: 0.9549081658919188\n",
      "Score for naive Bayes baseline: 0.8471904668170738\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression for fake news prediction\n",
    "classifier = LogisticRegression(max_iter = 10000) # konvergensen er fin btw, vi har ikke store ændringer i vores fejl, når\n",
    "# vi ændrer i antallet af iterationer.\n",
    "classifier.fit(x_train, y_train)\n",
    "score = classifier.score(x_test, y_test)\n",
    "print(f'Score for logistic baseline: {score}')\n",
    "\n",
    "# Naive Bayes for fake news prediction\n",
    "gnb = BernoulliNB()\n",
    "gnb.fit(x_train, y_train)\n",
    "score = gnb.score(x_test, y_test)\n",
    "print(f'Score for naive Bayes baseline: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32172b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "y_pred = classifier.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred, labels=all_news['type'].unique())\n",
    "df_cm = pd.DataFrame(cm, index=all_news['type'].unique(), columns=all_news['type'].unique())\n",
    "\n",
    "df_cm_percentage = df_cm.copy()\n",
    "for i in df_cm_percentage:\n",
    "    df_cm_percentage[i]=df_cm_percentage[i]/df_cm_percentage[i].sum()\n",
    "df_cm_percentage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8350efbc",
   "metadata": {},
   "source": [
    "#### Task 3: Creating a Fake News Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bbb413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use another model and use k-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d03a2c",
   "metadata": {},
   "source": [
    "#### Task 4: Performance Beyond the Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ffb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check på liar datasættet!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
